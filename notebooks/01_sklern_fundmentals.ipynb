{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Wprowadzenie do Scikit-Learn\n",
    "\n",
    "**Scikit-Learn** to jedna z najpopularniejszych bibliotek do uczenia maszynowego w języku Python. Jest to otwartoźródłowy pakiet, który oferuje łatwe w użyciu narzędzia do budowy i testowania modeli uczenia maszynowego, z naciskiem na klasyfikację, regresję, klasteryzację i przetwarzanie danych. Scikit-Learn bazuje na takich bibliotekach jak **NumPy**, **SciPy** i **matplotlib**, co pozwala na efektywne przetwarzanie danych i wizualizację wyników.\n",
    "\n",
    "## Główne Zalety Scikit-Learn\n",
    "1. **Łatwość Użycia**: Prosty i spójny interfejs API, który sprawia, że uczenie maszynowe jest przystępne nawet dla osób, które dopiero zaczynają.\n",
    "2. **Bogaty Zestaw Algorytmów**: Scikit-Learn oferuje szeroką gamę algorytmów uczenia nadzorowanego i nienadzorowanego, w tym klasyfikację, regresję, redukcję wymiarowości, oraz metody klasteryzacji.\n",
    "3. **Dobra Dokumentacja**: Pakiet posiada bardzo dobrą dokumentację oraz wiele przykładów, co ułatwia naukę i szybkie wdrażanie.\n",
    "4. **Skalowalność**: Idealny do prototypowania, z łatwością pozwala przeskalować modele na większe zbiory danych za pomocą innych narzędzi, takich jak TensorFlow czy PyTorch.\n",
    "\n",
    "Scikit-Learn jest idealnym narzędziem zarówno do nauki, jak i do szybkiego prototypowania modeli uczenia maszynowego. Dzięki intuicyjnemu interfejsowi, szerokiemu wachlarzowi funkcji i dobrej dokumentacji, jest to jeden z pierwszych wyborów dla każdego, kto zaczyna przygodę z uczeniem maszynowym w Pythonie oraz profesjonalistów wdrazających rozwiązania prdodukcyjne.\n",
    "\n",
    "## Materiały uzupełniające\n",
    "\n",
    "- **Dokumentacja scikit-learn** : https://scikit-learn.org/stable/\n",
    "- **Kurs Supervised Learning with Scikit-Learn na DC** https://app.datacamp.com/learn/courses/supervised-learning-with-scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie środowiska\n",
    "\n",
    "Instalacja najnowszych wersji pakietów (na dzień 25-10-2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn==1.5.2\n",
    "%pip install ydata-profiling==4.11.0\n",
    "%pip install ucimlrepo==0.0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po zainstalowaniu pakietów naley zrestartować środowisko -> Ikona restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pobieranie danych\n",
    "\n",
    "**Bank Marketing Data** \n",
    "Zbiór danych używany do przewidywania, czy klient banku skorzysta z oferty (subskrypcji) na podstawie takich cech, jak wiek, wykształcenie, zatrudnienie, kontakt z bankiem itp.\n",
    "\n",
    "Zródło danych i metadane: https://archive.ics.uci.edu/dataset/222/bank+marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing = fetch_ucirepo(id=222)\n",
    "\n",
    "features = bank_marketing.data.features\n",
    "target = bank_marketing.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podejzyj zaimportowaną datra frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# za pomocą dostępnych funkcji lub metod bibloteki pandas określ czy, ewentualnie które kolumny mają brakujące wartości i zlicz wystąpienia\n",
    "\n",
    "# Twój kod wykonaj ponizej:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdź czy typy kolumn po imporcie zgadzają się z zadeklarowanymi w dokumentacji datasetu\n",
    "# jeeli, któraś kolumna nie jest zaimportowana jako poprawny typ moe uyć metody astype() na obiekcie pd.DataFrame aby zmienić typ danych\n",
    "\n",
    "# Twój kod wykonaj ponizej:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# określ rozkłąd zmiennej celu 'targets' (jaki % kleintów skorzysta z subskrybcji)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksploracyjna Analiza Danych z uyciem ydata-profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pakiet ydata-profiling\n",
    "\n",
    "Pakiet **ydata-profiling** (wcześniej znany jako **pandas-profiling**) jest narzędziem służącym do szybkiego tworzenia kompleksowych raportów analizy eksploracyjnej danych (Exploratory Data Analysis, EDA) z wykorzystaniem danych przechowywanych w obiektach `pandas DataFrame`. Pakiet ten pozwala na automatyczne generowanie interaktywnego raportu HTML, który zawiera szczegółowe informacje o każdym atrybucie zbioru danych.\n",
    "\n",
    "**ydata-profiling** oferuje m.in.:\n",
    "1. **Podstawowe statystyki** – Oblicza podstawowe statystyki, takie jak średnia, mediana, min, max, wariancja, odchylenie standardowe itp. dla każdej kolumny.\n",
    "2. **Rozkład wartości** – Pokazuje rozkład wartości liczbowych i kategorycznych w każdej kolumnie, w tym histogramy i wykresy częstości.\n",
    "3. **Braki danych** – Wykrywa i raportuje brakujące wartości w kolumnach oraz pokazuje ich rozkład.\n",
    "4. **Korelacje** – Analizuje korelacje między kolumnami, dostarczając informacje na temat możliwych zależności.\n",
    "5. **Wykrywanie nieprawidłowości** – Identyfikuje potencjalne problemy, takie jak wartości odstające (outliers), duplikaty, oraz nietypowe wartości.\n",
    "6. **Podsumowanie danych** – Zawiera ogólną analizę i podsumowanie zbioru danych, co pozwala szybko zrozumieć strukturę i właściwości danych.\n",
    "\n",
    "Użycie **ydata-profiling** jest bardzo proste, wystarczy kilka wierszy kodu, aby wygenerować raport z obiektu `DataFrame`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Wczytanie danych\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Tworzenie raportu\n",
    "profile = ProfileReport(df, title=\"Raport Profilowania Danych\")\n",
    "profile.to_file(\"raport.html\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stwórz nową ramkę danych zawierającą wszytskie cechy i zmienną celu\n",
    "\n",
    "\n",
    "# Stwórz raort i wyeksportuj go do pliku. Przeanalizuj wyniki.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing danych w scikit-learn\n",
    "\n",
    "## Ćwiczenie: Preprocesor do uzupełniania brakujących wartości\n",
    "W uczeniu maszynowym przetwarzanie danych jest kluczowym krokiem, który wpływa na wydajność modeli. Scikit-Learn oferuje różne narzędzia do przetwarzania danych, takie jak:\n",
    "- **Imputer** (`SimpleImputer`) – do uzupełniania brakujących wartości\n",
    "- **Skalowanie cech** (`StandardScaler`, `MinMaxScaler`) – do normalizacji danych\n",
    "- **Kodowanie kategoryczne** (`OneHotEncoder`, `LabelEncoder`) – do przekształcania zmiennych kategorycznych na wartości numeryczne\n",
    "- **Normalizacja** (`Normalizer`) – do normalizacji danych do jednostkowej normy\n",
    "- **Redukcja wymiarowości** (`PCA`) – do zmniejszania liczby cech\n",
    "#\n",
    "W tym ćwiczeniu skupimy się na użyciu **SimpleImputer**, który jest preprocesorem do uzupełniania brakujących wartości w zbiorze danych.\n",
    "\n",
    "**Dokumentacja metod imputacji zmiennych**: https://scikit-learn.org/stable/modules/impute.html\n",
    "\n",
    "Zwróć uwagę na rónicę w metodach fit() i fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stwórz obiekt SimpleImputer i dopasuj go do danych, wykonaj imputację metodą właściwą dla danego typu danych\n",
    "\n",
    "\n",
    "# sprawdź czy braujące wartości zostały uzupełnione\n",
    "\n",
    "\n",
    "#Zakoduj dane kategoryczne metodą OneHot Encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podział zbioru na treningowy i testowy\n",
    "\n",
    "## Ćwiczenie: Dzielenie zbioru na uczący i testowy (80%/20%)\n",
    "\n",
    "W uczeniu maszynowym często potrzebujemy podzielić nasz zbiór danych na zbiór treningowy i testowy, aby móc ocenić wydajność naszego modelu na danych, które nie były używane podczas treningu. Scikit-Learn oferuje do tego celu funkcję `train_test_split` z modułu `model_selection`.\n",
    "\n",
    "Funkcja `train_test_split` przyjmuje kilka argumentów, z których najważniejsze to:\n",
    "- **`test_size`**: Określa proporcję danych, które mają zostać przeznaczone na zbiór testowy (np. `0.2` oznacza, że 20% danych zostanie użyte do testów).\n",
    "- **`random_state`**: Ustalając wartość `random_state`, możemy zagwarantować powtarzalność wyników podziału danych. Dzięki temu za każdym razem, gdy uruchomimy kod, podział danych będzie identyczny.\n",
    "- **`stratify`**: Argument `stratify` umożliwia dokonanie podziału danych z uwzględnieniem rozkładu zmiennej celu. Jeśli wskażemy zmienną celu jako wartość `stratify`, wówczas podział na zbiór treningowy i testowy będzie uwzględniał proporcje klas w oryginalnym zbiorze danych.\n",
    "\n",
    "Dokumentacja funkcji z przykłądami uzycia: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Podziel zbiór na uczący i testowy, zapewnij reprodukowalność losowania i stratyfikację\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trenowanie modeli klasyfikacyjnych\n",
    "\n",
    "W tej części nauczymy się trenować dwa popularne modele klasyfikacyjne: **Drzewo Decyzyjne** oraz **Las Losowy**. Oba modele należą do grupy algorytmów uczących się na podstawie drzewa decyzyjnego, a Las Losowy jest zespołem wielu drzew decyzyjnych, co zazwyczaj pozwala na uzyskanie lepszej jakości klasyfikacji.\n",
    "\n",
    "- **Dokumentacja klasyfikatora Drzewa Decyzyjnego**: https://scikit-learn.org/stable/modules/tree.html#classification\n",
    "- **Dokumentacja klasyfikatora Lasu Losowego** https://scikit-learn.org/stable/modules/ensemble.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zadania:\n",
    "\n",
    "# 1. Wytrenuj model drzewa decyzyjnego i lasu losowego (z uzyciem domyslnych parametrów)\n",
    "# 2. Dokonaj predykcji na danych treningowych i tesotwych (medota predict() i predict_proba())\n",
    "\n",
    "# Obikety wytrenowanych modeli oraz wyniki predykcji zapisz do zmiennych\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porównanie klasyfikatorów\n",
    "\n",
    "W tym ćwiczeniu porównamy wydajność wytrenowanych modeli na danych testowych. Użyjemy do tego **macierzy konfuzji** oraz **classification_report**, które dostarczają szczegółowych informacji na temat wyników klasyfikacji.\n",
    "\n",
    "- **Dokumentacja confusion_matrix** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix\n",
    "- **Dokumentacja classifiction_report** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dla Drzewa decyzyjnego oraz lasu losowego wygeneruj macierz konfucji i raport klasyfikacji\n",
    "# Zrób to dla danych testowych i treningowych, porównaj wyniki\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wait-proj-template",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
